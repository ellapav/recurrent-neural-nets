{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using Tensorflow version 1.15\n",
    "import keras\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasource references\n",
    "# https://keras.io/datasets/\n",
    "# https://keras.io/preprocessing/sequence/\n",
    "\n",
    "# fix issues with pickle: https://stackoverflow.com/questions/55890813/how-to-fix-object-arrays-cannot-be-loaded-when-allow-pickle-false-for-imdb-loa/56243777\n",
    "np_load_old = np.load # save np.load\n",
    "np.load = lambda *a,**k: np_load_old(*a, allow_pickle=True, **k) # modify the default parameters of np.load\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=5000)\n",
    " # x<-> data features, y<-> labels \n",
    "\n",
    "np.load = np_load_old # restore np.load for future normal usage\n",
    "\n",
    "# pad the data\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=500)\n",
    "x_test =  keras.preprocessing.sequence.pad_sequences(x_test, maxlen=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 500)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the RNN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Network\n",
    "def build_model(vector_length, hidden_states):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Embedding layer\n",
    "    # https://keras.io/layers/embeddings/\n",
    "    model.add(Embedding(input_dim=5000, output_dim=vector_length, input_length = 500))\n",
    "    \n",
    "    #LSTM layer\n",
    "    # https://keras.io/examples/conv_lstm/\n",
    "    # https://keras.io/layers/recurrent/\n",
    "    model.add(LSTM(units = hidden_states))\n",
    "\n",
    "    #Output layer\n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    #Adam optimizer, crossentropy as loss function\n",
    "    model.compile(loss=keras.losses.binary_crossentropy, optimizer='adam',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Kept getting error messages without this line\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "\n",
    "# #Test it's running properly\n",
    "# model = build_model(vector_length=8, hidden_states=16) \n",
    "\n",
    "# results = model.fit(x_train, y_train, \n",
    "#                         epochs=2, \n",
    "#                         verbose=1)\n",
    "\n",
    "\n",
    "# score = model.evaluate(x_test, y_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the function is running properly \n",
    "### We expect that we can use build_model to train the model for specific hyperparameter values, then see how the model performs on the test data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 264s 11ms/step - loss: 0.4639 - acc: 0.7760\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 262s 10ms/step - loss: 0.3159 - acc: 0.8727\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 0.2902 - acc: 0.8832\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 258s 10ms/step - loss: 0.2556 - acc: 0.9016\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 257s 10ms/step - loss: 0.2167 - acc: 0.9176\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.1962 - acc: 0.9248\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.1803 - acc: 0.9322\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.1598 - acc: 0.9409\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.1292 - acc: 0.9549\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 255s 10ms/step - loss: 0.1265 - acc: 0.9549\n",
      "0.85692\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "        \n",
    "model = build_model(16, 64) \n",
    "\n",
    "#Train the model \n",
    "results = model.fit(x_train, y_train, \n",
    "                            epochs=10, \n",
    "                            verbose=1)\n",
    "\n",
    "#Use the test data in the model and see how it performs \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "\n",
    "print(score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Test the models \n",
    "### Re-run the model using various hyperparameter combinations \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.  16.  32.  64. 128.]\n",
      " [  8.   0.   0.   0.   0.]\n",
      " [ 16.   0.   0.   0.   0.]\n",
      " [ 32.   0.   0.   0.   0.]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.4523 - acc: 0.7801\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 211s 8ms/step - loss: 0.2822 - acc: 0.8894\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 211s 8ms/step - loss: 0.2396 - acc: 0.9091\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.2116 - acc: 0.9209\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.1930 - acc: 0.9285\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 220s 9ms/step - loss: 0.1775 - acc: 0.9334\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.1658 - acc: 0.9382\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.1548 - acc: 0.9435\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 216s 9ms/step - loss: 0.1370 - acc: 0.9513\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1266 - acc: 0.9552\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.        0.        0.     ]\n",
      " [ 16.        0.        0.        0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 236s 9ms/step - loss: 0.4632 - acc: 0.7745\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 225s 9ms/step - loss: 0.2954 - acc: 0.8806\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.2537 - acc: 0.8989\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.2197 - acc: 0.9140\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.1987 - acc: 0.9255\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.1841 - acc: 0.9292\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.1749 - acc: 0.9342\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 230s 9ms/step - loss: 0.1700 - acc: 0.9365\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 230s 9ms/step - loss: 0.1517 - acc: 0.9445\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 230s 9ms/step - loss: 0.1470 - acc: 0.9456\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.        0.     ]\n",
      " [ 16.        0.        0.        0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 254s 10ms/step - loss: 0.5061 - acc: 0.7451\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 251s 10ms/step - loss: 0.3354 - acc: 0.8620\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 251s 10ms/step - loss: 0.2783 - acc: 0.8901\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 251s 10ms/step - loss: 0.2523 - acc: 0.9014\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.2466 - acc: 0.9038\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 245s 10ms/step - loss: 0.2066 - acc: 0.9216\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 246s 10ms/step - loss: 0.1916 - acc: 0.9290\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 246s 10ms/step - loss: 0.1908 - acc: 0.9289\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 246s 10ms/step - loss: 0.1777 - acc: 0.9336\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 246s 10ms/step - loss: 0.1511 - acc: 0.9464\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.     ]\n",
      " [ 16.        0.        0.        0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 295s 12ms/step - loss: 0.5114 - acc: 0.7370\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 291s 12ms/step - loss: 0.3400 - acc: 0.8594\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 290s 12ms/step - loss: 0.2857 - acc: 0.8850\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 297s 12ms/step - loss: 0.2334 - acc: 0.9099\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.2214 - acc: 0.9146\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.1847 - acc: 0.9310\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.1568 - acc: 0.9428\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 303s 12ms/step - loss: 0.1476 - acc: 0.9461\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.1283 - acc: 0.9548\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 297s 12ms/step - loss: 0.1181 - acc: 0.9568\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.        0.        0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 216s 9ms/step - loss: 0.4343 - acc: 0.7994\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.2779 - acc: 0.8908\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.2400 - acc: 0.9097\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.2124 - acc: 0.9202\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 213s 9ms/step - loss: 0.1885 - acc: 0.9295\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1718 - acc: 0.9360\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 212s 8ms/step - loss: 0.1910 - acc: 0.9242\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.1794 - acc: 0.9326\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1340 - acc: 0.9524\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 213s 9ms/step - loss: 0.1273 - acc: 0.9546\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.        0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 229s 9ms/step - loss: 0.4324 - acc: 0.7969\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 225s 9ms/step - loss: 0.2855 - acc: 0.8874\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.2583 - acc: 0.8967\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 225s 9ms/step - loss: 0.2167 - acc: 0.9179\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 224s 9ms/step - loss: 0.1938 - acc: 0.9257\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.2136 - acc: 0.9172\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.2056 - acc: 0.9216\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.1876 - acc: 0.9296\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.1591 - acc: 0.9403\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 222s 9ms/step - loss: 0.1391 - acc: 0.9499\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.        0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 261s 10ms/step - loss: 0.4512 - acc: 0.7758\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 256s 10ms/step - loss: 0.3114 - acc: 0.8706\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.2573 - acc: 0.8996\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.2247 - acc: 0.9131\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.2252 - acc: 0.9120\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.1929 - acc: 0.9276\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 248s 10ms/step - loss: 0.1582 - acc: 0.9418\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.1577 - acc: 0.9401\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.1262 - acc: 0.9529\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 249s 10ms/step - loss: 0.1192 - acc: 0.9570\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.     ]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 289s 12ms/step - loss: 0.4941 - acc: 0.7592\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 289s 12ms/step - loss: 0.3421 - acc: 0.8599\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 299s 12ms/step - loss: 0.3014 - acc: 0.8767\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 299s 12ms/step - loss: 0.2688 - acc: 0.8933\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 300s 12ms/step - loss: 0.2595 - acc: 0.8947\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 299s 12ms/step - loss: 0.2250 - acc: 0.9151\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 300s 12ms/step - loss: 0.1898 - acc: 0.9288\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 299s 12ms/step - loss: 0.1742 - acc: 0.9350\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 299s 12ms/step - loss: 0.1478 - acc: 0.9460\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 301s 12ms/step - loss: 0.1281 - acc: 0.9536\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.87156]\n",
      " [ 32.        0.        0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 217s 9ms/step - loss: 0.4269 - acc: 0.8010\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.2570 - acc: 0.8983\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.2230 - acc: 0.9148\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.2017 - acc: 0.9218\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1694 - acc: 0.9370\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1737 - acc: 0.9319\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1690 - acc: 0.9364\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 215s 9ms/step - loss: 0.1208 - acc: 0.9566\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.1106 - acc: 0.9613\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 214s 9ms/step - loss: 0.0958 - acc: 0.9679\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.87156]\n",
      " [ 32.        0.87184   0.        0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 235s 9ms/step - loss: 0.4119 - acc: 0.8157\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 233s 9ms/step - loss: 0.2809 - acc: 0.8882\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 227s 9ms/step - loss: 0.2321 - acc: 0.9091\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.2053 - acc: 0.9218\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 227s 9ms/step - loss: 0.1872 - acc: 0.9298\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1669 - acc: 0.9370\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 228s 9ms/step - loss: 0.1943 - acc: 0.9293\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1364 - acc: 0.9488\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 230s 9ms/step - loss: 0.1364 - acc: 0.9494\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 226s 9ms/step - loss: 0.1223 - acc: 0.9549\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.87156]\n",
      " [ 32.        0.87184   0.86748   0.        0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 268s 11ms/step - loss: 0.4215 - acc: 0.8060\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 263s 11ms/step - loss: 0.3104 - acc: 0.8754\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 260s 10ms/step - loss: 0.2437 - acc: 0.9040\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.2152 - acc: 0.9178\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1835 - acc: 0.9300\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1584 - acc: 0.9406\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1512 - acc: 0.9430\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1601 - acc: 0.9409\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.1155 - acc: 0.9582\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 259s 10ms/step - loss: 0.2289 - acc: 0.9066\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.87156]\n",
      " [ 32.        0.87184   0.86748   0.8522    0.     ]]\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 290s 12ms/step - loss: 0.4649 - acc: 0.7808\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.4057 - acc: 0.8334\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 305s 12ms/step - loss: 0.3113 - acc: 0.8740\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 306s 12ms/step - loss: 0.2574 - acc: 0.8999\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 301s 12ms/step - loss: 0.2242 - acc: 0.9135\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 294s 12ms/step - loss: 0.1885 - acc: 0.9294\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 294s 12ms/step - loss: 0.1654 - acc: 0.9392\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 298s 12ms/step - loss: 0.1545 - acc: 0.9428\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 305s 12ms/step - loss: 0.1238 - acc: 0.9546\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 305s 12ms/step - loss: 0.1143 - acc: 0.9589\n",
      "[[  0.       16.       32.       64.      128.     ]\n",
      " [  8.        0.85628   0.86432   0.85848   0.86516]\n",
      " [ 16.        0.86448   0.86448   0.69164   0.87156]\n",
      " [ 32.        0.87184   0.86748   0.8522    0.86656]]\n"
     ]
    }
   ],
   "source": [
    "#the possible hyperparameter values \n",
    "vector_length = np.array([8,16,32])\n",
    "hidden_states = np.array([16,32,64,128])\n",
    "\n",
    "#initialize a matrix which tracks the accuracy for each hyperparameter combo \n",
    "testing_accuracy = np.zeros([4,5])\n",
    "testing_accuracy[1:4,0] = vector_length\n",
    "testing_accuracy[0,1:5] = hidden_states\n",
    "\n",
    "#check it initialized with zeros \n",
    "print(testing_accuracy)\n",
    "\n",
    "epochs = 10\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        K.clear_session()\n",
    "        \n",
    "        #tell the model which hyperparameters to use \n",
    "        model = build_model(vector_length[i], hidden_states[j]) \n",
    "\n",
    "        #train the model \n",
    "        results = model.fit(x_train, y_train, \n",
    "                            epochs=epochs, \n",
    "                            verbose=1)\n",
    "\n",
    "        #see how the model performs on the test data \n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        \n",
    "        testing_accuracy[i+1,j+1] = score[1]\n",
    "\n",
    "        print(testing_accuracy)"
   ]
  }
